import pandas as pd
import numpy as np
import datetime # datetime preprocessing
import utils # made by author for efficiently dealing with data
from datetime import datetime

##################################
# loading data
##################################
train = pd.read_csv('../input/train.csv.gz', compression='gzip', dtype={'ProductID': str})
test = pd.read_csv('../input/test.csv.gz', compression='gzip', dtype={'ProductID': str})

print('loading finish')

##################################
# pre-processing
##################################

# convert query_datetime(str type) column to datetime type
train['query_datetime'] = pd.to_datetime(train.query_datetime)
test['query_datetime'] = pd.to_datetime(test.query_datetime)

print('pre-processing done')


def overlap_time(x):
    '''
    conpute number of overlap in a specific computer program
    
    
    parameters:
    --------
    x: DataFrame
    '''

    t = 0
    t_1 = datetime.strptime('1992-10-30', '%Y-%m-%d') # initial point
    col = ['first_time','last_time']
    x = x.sort_values(by = 'first_time')
    #print(x[col])
    for ix,row in x[col].iterrows():
        # row[0]: first_time
        # row[1]: last_time
        if row[0] >= t_1:
            # 這筆資料的first_time 發生在上一筆資料last_time之後
            pass
        else:
            t += (t_1 - row[0]).total_seconds()
        t_1 = row[1]    
    x['overlap_time_in_sec'] = t
    x['overlap_time_in_min'] = t / 60
    x['overlap_time_in_hour'] = t / 60 / 60
    return x.drop(col+['CustomerID'], axis = 1)
    
#-------------------------
# train
#-------------------------
#計算每個消費者個別使用此程式的持續時間 in sec
df1 = train.groupby(by = ['id','CustomerID']).query_datetime.min().to_frame('first_time')
df2 = train.groupby(by = ['id','CustomerID']).query_datetime.max().to_frame('last_time')
train = pd.concat([df1,df2], axis =1)

del df1,df2
train = train.reset_index('id').reset_index('CustomerID')
train = train.groupby('id').apply(overlap_time).drop_duplicates('id').set_index('id').reset_index()

#-------------------------
# test
#-------------------------

df1 = test.groupby(by = ['id','CustomerID']).query_datetime.min().to_frame('first_time')
df2 = test.groupby(by = ['id','CustomerID']).query_datetime.max().to_frame('last_time')
test = pd.concat([df1,df2], axis =1)

del df1,df2
test = test.reset_index('id').reset_index('CustomerID')
test = test.groupby('id').apply(overlap_time).drop_duplicates('id').set_index('id').reset_index()

#-------------------------
#save
#-------------------------

train.to_csv('../feature/{}/overlap_time.csv.gz'.format('train'), index = False, compression='gzip')
test.to_csv('../feature/{}/overlap_time.csv.gz'.format('test'), index = False, compression='gzip')
