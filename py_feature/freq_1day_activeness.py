import pandas as pd
import numpy as np
import datetime # datetime preprocessing
import utils # made by author for efficiently dealing with data

##################################
# loading data
##################################
train = pd.read_csv('../input/train.csv.gz', compression='gzip', dtype={'ProductID': str})
test = pd.read_csv('../input/test.csv.gz', compression='gzip', dtype={'ProductID': str})

print('loading finish')

##################################
# pre-processing
##################################

# convert query_datetime(str type) column to datetime type
train['query_datetime'] = pd.to_datetime(train.query_datetime)
test['query_datetime'] = pd.to_datetime(test.query_datetime)

print('pre-processing done')

##################################
# using global window to capture local pattern
##################################
def prior_period_state(x):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    prior_period_point = x.query_datetime.min() + delta / 3
    middle_period_point = x.query_datetime.min() + 2 * delta/3
    #selecting df based on time period
    prior_df = x[x.query_datetime <= prior_period_point]
    if prior_df.empty:
        return 0
    else:
        return prior_df.interval_count.sum()
def middle_period_state(x):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    prior_period_point = x.query_datetime.min() + delta / 3
    middle_period_point = x.query_datetime.min() + 2 * delta/3
    #selecting df based on time period
    middle_df = x[(x.query_datetime > prior_period_point ) 
         & (x.query_datetime <= middle_period_point )]
    if middle_df.empty:
        return 0
    else:
        return middle_df.interval_count.sum()    
def last_period_state(x):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    prior_period_point = x.query_datetime.min() + delta / 3
    middle_period_point = x.query_datetime.min() + 2 * delta/3
    #selecting df based on time period
    last_df = x[x.query_datetime > middle_period_point]
    if last_df.empty:
        return 0
    else:
        return last_df.interval_count.sum()    

group_freq = '1440min'
interval = 3
#-------------------------
#train
#-------------------------
df1 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df1 = df1.reset_index('query_datetime').reset_index('id')
df1 = df1.groupby('id').apply(prior_period_state).to_frame('prior_period_count')
df1 = df1.reset_index()

df2 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df2 = df2.reset_index('query_datetime').reset_index('id')
df2 = df2.groupby('id').apply(middle_period_state).to_frame('middle_period_count')
df2 = df2.reset_index()

df3 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df3 = df3.reset_index('query_datetime').reset_index('id')
df3 = df3.groupby('id').apply(last_period_state).to_frame('last_period_count')
df3 = df3.reset_index()

#merge
train = pd.merge(df1,df2,on='id',how='left')
train = pd.merge(train,df3,on='id',how='left')
train = train.add_suffix('-interval_{}_freq_{}'.format(interval,group_freq)) \
.rename(columns={'id-interval_{}_freq_{}'.format(interval,group_freq): 'id'})
del df1,df2,df3
#-------------------------
#test
#-------------------------
df1 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df1 = df1.reset_index('query_datetime').reset_index('id')
df1 = df1.groupby('id').apply(prior_period_state).to_frame('prior_period_count')
df1 = df1.reset_index()

df2 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df2 = df2.reset_index('query_datetime').reset_index('id')
df2 = df2.groupby('id').apply(middle_period_state).to_frame('middle_period_count')
df2 = df2.reset_index()

df3 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df3 = df3.reset_index('query_datetime').reset_index('id')
df3 = df3.groupby('id').apply(last_period_state).to_frame('last_period_count')
df3 = df3.reset_index()

#merge
test = pd.merge(df1,df2,on='id',how='left')
test = pd.merge(test,df3,on='id',how='left')
test = test.add_suffix('-interval_{}_freq_{}'.format(interval,group_freq)) \
.rename(columns={'id-interval_{}_freq_{}'.format(interval,group_freq): 'id'})
del df1,df2,df3

#-------------------------
#save
#-------------------------

train.to_csv('../feature/{}/global_window_{}_local_pattern_{}.csv.gz'.format('train',interval,group_freq), index = False, compression='gzip')
test.to_csv('../feature/{}/global_window_{}_local_pattern_{}.csv.gz'.format('test',interval,group_freq), index = False, compression='gzip')





