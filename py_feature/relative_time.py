import pandas as pd
import numpy as np
import datetime # datetime preprocessing
import utils # made by author for efficiently dealing with data
from math import ceil 

##################################
# loading data
##################################
train = pd.read_csv('../input/train.csv.gz', compression='gzip', dtype={'ProductID': str})
test = pd.read_csv('../input/test.csv.gz', compression='gzip', dtype={'ProductID': str})

print('loading finish')
##################################
# pre-processing
##################################

# ProductID Cleaning
train['ProductID'] = train.ProductID.map(str)
train['ProductID'] = train.ProductID.apply(lambda x: '055649' if x == '55649' else x)
test['ProductID'] = test.ProductID.map(str)
test['ProductID'] = test.ProductID.apply(lambda x: '055649' if x == '55649' else x)

# convert query_datetime(str type) column to datetime type
train['query_datetime'] = pd.to_datetime(train.query_datetime)
test['query_datetime'] = pd.to_datetime(test.query_datetime)

print('pre-processing done')

def week_of_month(dt):
    """ 
    Returns the week of the month for the specified date.
    
    parameters
    -----
    dt: datetime64[ns]
    
    """
    first_day = dt.replace(day=1) # the day of month for the date(dt)
    dom = dt.day # Between 1 and the number of days in the given month of the given year(30 or 31 like that).
    adjusted_dom = dom + first_day.weekday() # Return the day of the week as an integer, where Monday is 0 and Sunday is 6
    return int(ceil(adjusted_dom/7.0))


#-----------
# datetime feature preprocessing
#-----------

# 一個月中的第幾個禮拜[0~3]
train['event_week_of_month'] = train['query_datetime'].apply(week_of_month)
# 一個月中的第幾天[0~29 or 0-30]
train['event_day_of_the_month'] = train['query_datetime'].dt.day 
# Convert date time to the day of the week [0~6]. For example, Monday is 0 and Sunday is 6. 
train['event_day_of_the_week'] = train['query_datetime'].dt.weekday 
# Convert date time to the hour of the day [0~23]
train['event_hour_of_the_day'] = train['query_datetime'].dt.hour
# Convert date time to the min of the hour [0~59]
train['event_min_of_the_hour'] = train['query_datetime'].dt.minute
# Convert date time to the sec of the min [0~59]
train['event_sec_of_the_min'] = train['query_datetime'].dt.second


# 一個月中的第幾個禮拜[0~3]
test['event_week_of_month'] = test['query_datetime'].apply(week_of_month)
# 一個月中的第幾天[0~29 or 0-30]
test['event_day_of_the_month'] = test['query_datetime'].dt.day 
# Convert date time to the day of the week [0~6]. For example, Monday is 0 and Sunday is 6. 
test['event_day_of_the_week'] = test['query_datetime'].dt.weekday 
# Convert date time to the hour of the day [0~23]
test['event_hour_of_the_day'] = test['query_datetime'].dt.hour
# Convert date time to the min of the hour [0~59]
test['event_min_of_the_hour'] = test['query_datetime'].dt.minute
# Convert date time to the sec of the min [0~59]
test['event_sec_of_the_min'] = test['query_datetime'].dt.second



#-------------------------
# train
#-------------------------
'''
Note that:
    需要保留時間標記 for validation splitting by timer 
'''
df1 = train.groupby(by = ['id']).mean().add_prefix('mean-') \
.rename(columns={'mean-label': 'label'}) \
.reset_index()
df1.drop('label', axis = 1, inplace = True)

df2 = train.groupby('id').std().add_prefix('std-') \
.rename(columns={'std-label': 'label'}).reset_index().drop('label', axis = 1)

df3 = train.groupby('id').min().add_prefix('min-' ) \
.rename(columns={'min-label': 'label'}).reset_index().drop('label', axis = 1) \
.drop(['min-CustomerID','min-query_datetime','min-ProductID'], axis = 1)

df4 = train.groupby('id').max().add_prefix('max-') \
.rename(columns={'max-label': 'label'}).reset_index().drop('label', axis = 1) \
.drop(['max-CustomerID','max-query_datetime','max-ProductID'], axis = 1)

df5 = train.groupby('id').median().add_prefix('median-')\
.rename(columns={'median-label': 'label'}).reset_index().drop('label', axis = 1)


train = pd.merge(df1, df2, on ='id', how = 'left')
train = pd.merge(train,df3, on ='id', how = 'left')
train = pd.merge(train,df4, on ='id', how = 'left')
train = pd.merge(train,df5, on ='id', how = 'left')
del df1, df2, df3, df4, df5

#-------------------------
# test
#-------------------------
df1 = test.groupby(by = ['id']).mean().add_prefix('mean-') \
.rename(columns={'mean-label': 'label'}) \
.reset_index()
df1.drop('label', axis = 1, inplace = True)

df2 = test.groupby('id').std().add_prefix('std-') \
.rename(columns={'std-label': 'label'}).reset_index().drop('label', axis = 1)

df3 = test.groupby('id').min().add_prefix('min-' ) \
.rename(columns={'min-label': 'label'}).reset_index().drop('label', axis = 1) \
.drop(['min-CustomerID','min-query_datetime','min-ProductID'], axis = 1)

df4 = test.groupby('id').max().add_prefix('max-') \
.rename(columns={'max-label': 'label'}).reset_index().drop('label', axis = 1) \
.drop(['max-CustomerID','max-query_datetime','max-ProductID'], axis = 1)

df5 = test.groupby('id').median().add_prefix('median-')\
.rename(columns={'median-label': 'label'}).reset_index().drop('label', axis = 1)


test = pd.merge(df1, df2, on ='id', how = 'left')
test = pd.merge(test,df3, on ='id', how = 'left')
test = pd.merge(test,df4, on ='id', how = 'left')
test = pd.merge(test,df5, on ='id', how = 'left')
del df1, df2, df3, df4, df5

#-------------------------
#save
#-------------------------
utils.mkdir_p('../feature/train')
utils.mkdir_p('../feature/test')

train.to_csv('../feature/{}/program_relative_time.csv.gz'.format('train'), index = False, compression='gzip')
test.to_csv('../feature/{}/program_relative_time.csv.gz'.format('test'), index = False, compression='gzip')


