import pandas as pd
import numpy as np
import datetime # datetime preprocessing
import utils # made by author for efficiently dealing with data

##################################
# loading data
##################################
train = pd.read_csv('../input/train.csv.gz', compression='gzip', dtype={'ProductID': str})
test = pd.read_csv('../input/test.csv.gz', compression='gzip', dtype={'ProductID': str})

print('loading finish')

##################################
# pre-processing
##################################

# convert query_datetime(str type) column to datetime type
train['query_datetime'] = pd.to_datetime(train.query_datetime)
test['query_datetime'] = pd.to_datetime(test.query_datetime)



#-------------------------
# train
#-------------------------
#每一個程式觸及到多少人
train = train.groupby(by = ['id','CustomerID']).count() \
.reset_index('CustomerID').groupby('id').count() \
.rename(columns = {'CustomerID': 'count_customer'})[['count_customer']].reset_index()

##some features with largest, we perform log transformation
train['log_count_customer'] = np.log(train.count_customer)


#-------------------------
# test
#-------------------------
#每一個程式觸及到多少人
test = test.groupby(by = ['id','CustomerID']).count() \
.reset_index('CustomerID').groupby('id').count() \
.rename(columns = {'CustomerID': 'count_customer'})[['count_customer']].reset_index()

##some features with largest, we perform log transformation
test['log_count_customer'] = np.log(test.count_customer)

#-------------------------
#save
#-------------------------

train.to_csv('../feature/{}/num_user.csv.gz'.format('train'), index = False, compression='gzip')
test.to_csv('../feature/{}/num_user.csv.gz'.format('test'), index = False, compression='gzip')

