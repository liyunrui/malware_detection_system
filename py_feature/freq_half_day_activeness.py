import pandas as pd
import numpy as np
import datetime # datetime preprocessing
import utils # made by author for efficiently dealing with data

##################################
# loading data
##################################
train = pd.read_csv('../input/train.csv.gz', compression='gzip', dtype={'ProductID': str})
test = pd.read_csv('../input/test.csv.gz', compression='gzip', dtype={'ProductID': str})

print('loading finish')

##################################
# pre-processing
##################################

# convert query_datetime(str type) column to datetime type
train['query_datetime'] = pd.to_datetime(train.query_datetime)
test['query_datetime'] = pd.to_datetime(test.query_datetime)

print('pre-processing done')

##################################
# using global window to capture local pattern
##################################
def first_period_state(x, interval = 6):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    interval: int
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    local_window = delta/ interval
    segment_period_point = []
    for i in range(interval):
        time_period = x.query_datetime.min() + (i+1) * local_window
        segment_period_point.append(time_period)
    #selecting df based on time period
    prior_df = x[x.query_datetime <= segment_period_point[0]]
    if prior_df.empty:
        return 0
    else:
        return prior_df.interval_count.sum()
def second_period_state(x, interval = 6):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    interval: int
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    local_window = delta/ interval
    segment_period_point = []
    for i in range(interval):
        time_period = x.query_datetime.min() + (i+1) * local_window
        segment_period_point.append(time_period)
    #selecting df based on time period
    prior_df = x[(x.query_datetime > segment_period_point[0] ) 
         & (x.query_datetime <= segment_period_point[1] )]
    if prior_df.empty:
        return 0
    else:
        return prior_df.interval_count.sum()        
def third_period_state(x, interval = 6):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    interval: int
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    local_window = delta/ interval
    segment_period_point = []
    for i in range(interval):
        time_period = x.query_datetime.min() + (i+1) * local_window
        segment_period_point.append(time_period)
    #selecting df based on time period
    prior_df = x[(x.query_datetime > segment_period_point[1] ) 
         & (x.query_datetime <= segment_period_point[2] )]
    if prior_df.empty:
        return 0
    else:
        return prior_df.interval_count.sum()    
def fourth_period_state(x, interval = 6):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    interval: int
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    local_window = delta/ interval
    segment_period_point = []
    for i in range(interval):
        time_period = x.query_datetime.min() + (i+1) * local_window
        segment_period_point.append(time_period)
    #selecting df based on time period
    prior_df = x[(x.query_datetime > segment_period_point[2] ) 
         & (x.query_datetime <= segment_period_point[3] )]
    if prior_df.empty:
        return 0
    else:
        return prior_df.interval_count.sum()     
def fifth_period_state(x, interval = 6):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    interval: int
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    local_window = delta/ interval
    segment_period_point = []
    for i in range(interval):
        time_period = x.query_datetime.min() + (i+1) * local_window
        segment_period_point.append(time_period)
    #selecting df based on time period
    prior_df = x[(x.query_datetime > segment_period_point[3] ) 
         & (x.query_datetime <= segment_period_point[4] )]
    if prior_df.empty:
        return 0
    else:
        return prior_df.interval_count.sum()    
def sixth_period_state(x, interval = 6):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    interval: int
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    local_window = delta/ interval
    segment_period_point = []
    for i in range(interval):
        time_period = x.query_datetime.min() + (i+1) * local_window
        segment_period_point.append(time_period)
    #selecting df based on time period
    prior_df = x[(x.query_datetime > segment_period_point[4] ) ]
    if prior_df.empty:
        return 0
    else:
        return prior_df.interval_count.sum()  



group_freq = '720min'
interval = 6

#-------------------------
#train
#-------------------------
df1 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df1 = df1.reset_index('query_datetime').reset_index('id')
df1 = df1.groupby('id').apply(first_period_state).to_frame('first_period_state')
df1 = df1.reset_index()

df2 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df2 = df2.reset_index('query_datetime').reset_index('id')
df2 = df2.groupby('id').apply(second_period_state).to_frame('second_period_state')
df2 = df2.reset_index()

df3 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df3 = df3.reset_index('query_datetime').reset_index('id')
df3 = df3.groupby('id').apply(third_period_state).to_frame('third_period_state')
df3 = df3.reset_index()

df4 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df4 = df4.reset_index('query_datetime').reset_index('id')
df4 = df4.groupby('id').apply(fourth_period_state).to_frame('fourth_period_state')
df4 = df4.reset_index()

df5 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df5 = df5.reset_index('query_datetime').reset_index('id')
df5 = df5.groupby('id').apply(fifth_period_state).to_frame('fifth_period_state')
df5 = df5.reset_index()

df6 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df6 = df6.reset_index('query_datetime').reset_index('id')
df6 = df6.groupby('id').apply(sixth_period_state).to_frame('sixth_period_state')
df6 = df6.reset_index()

#merge
train = pd.merge(df1,df2,on='id',how='left')
train = pd.merge(train,df3,on='id',how='left')
train = pd.merge(train,df4,on='id',how='left')
train = pd.merge(train,df5,on='id',how='left')
train = pd.merge(train,df6,on='id',how='left')
train = train.add_suffix('-interval_{}_freq_{}'.format(interval,group_freq)) \
.rename(columns={'id-interval_{}_freq_{}'.format(interval,group_freq): 'id'})
del df1,df2,df3,df4,df5,df6
#-------------------------
#test
#-------------------------
df1 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df1 = df1.reset_index('query_datetime').reset_index('id')
df1 = df1.groupby('id').apply(first_period_state).to_frame('first_period_state')
df1 = df1.reset_index()

df2 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df2 = df2.reset_index('query_datetime').reset_index('id')
df2 = df2.groupby('id').apply(second_period_state).to_frame('second_period_state')
df2 = df2.reset_index()

df3 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df3 = df3.reset_index('query_datetime').reset_index('id')
df3 = df3.groupby('id').apply(third_period_state).to_frame('third_period_state')
df3 = df3.reset_index()

df4 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df4 = df4.reset_index('query_datetime').reset_index('id')
df4 = df4.groupby('id').apply(fourth_period_state).to_frame('fourth_period_state')
df4 = df4.reset_index()

df5 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df5 = df5.reset_index('query_datetime').reset_index('id')
df5 = df5.groupby('id').apply(fifth_period_state).to_frame('fifth_period_state')
df5 = df5.reset_index()

df6 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq) ]).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'interval_count'})
df6 = df6.reset_index('query_datetime').reset_index('id')
df6 = df6.groupby('id').apply(sixth_period_state).to_frame('sixth_period_state')
df6 = df6.reset_index()

#merge
test = pd.merge(df1,df2,on='id',how='left')
test = pd.merge(test,df3,on='id',how='left')
test = pd.merge(test,df4,on='id',how='left')
test = pd.merge(test,df5,on='id',how='left')
test = pd.merge(test,df6,on='id',how='left')
test = test.add_suffix('-interval_{}_freq_{}'.format(interval,group_freq)) \
.rename(columns={'id-interval_{}_freq_{}'.format(interval,group_freq): 'id'})
del df1,df2,df3,df4,df5,df6

#-------------------------
#save
#-------------------------

train.to_csv('../feature/{}/global_window_{}_local_pattern_{}.csv.gz'.format('train',interval,group_freq), index = False, compression='gzip')
test.to_csv('../feature/{}/global_window_{}_local_pattern_{}.csv.gz'.format('test',interval,group_freq), index = False, compression='gzip')



