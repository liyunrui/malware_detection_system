import pandas as pd
import numpy as np
import datetime # datetime preprocessing
import utils # made by author for efficiently dealing with data

##################################
# loading data
##################################
train = pd.read_csv('../input/train.csv.gz', compression='gzip', dtype={'ProductID': str})
test = pd.read_csv('../input/test.csv.gz', compression='gzip', dtype={'ProductID': str})

print('loading finish')

##################################
# pre-processing
##################################

# convert query_datetime(str type) column to datetime type
train['query_datetime'] = pd.to_datetime(train.query_datetime)
test['query_datetime'] = pd.to_datetime(test.query_datetime)


def psersonal_duration_estimation(x):
    '''
    duration in sec

    std:代表的是數值的分散程度
    
    parameters:
    --------
    x: DataFrame
    '''
    x['std-psersonal_duration_in_sec'] = x.psersonal_duration_in_sec.std()
    x['mean-psersonal_duration_in_sec'] = x.psersonal_duration_in_sec.mean()
    x['min-psersonal_duration_in_sec'] = x.psersonal_duration_in_sec.min()
    x['max-psersonal_duration_in_sec'] = x.psersonal_duration_in_sec.max()
    #remove useful columns
    x.drop(['first_time','last_time','psersonal_duration_in_sec'], axis = 1, inplace = True)
    return x

#-------------------------
# train
#-------------------------

df1 = train.groupby(by = ['id','CustomerID']).query_datetime.min().to_frame('first_time')
df2 = train.groupby(by = ['id','CustomerID']).query_datetime.max().to_frame('last_time')
train = pd.concat([df1,df2], axis =1)
del df1, df2
#計算每個消費者個別使用此程式的持續時間
train['psersonal_duration_in_sec'] = (train['last_time'] - train['first_time']).map(lambda x: x.total_seconds())

train = train.groupby('id').apply(psersonal_duration_estimation).reset_index() \
.drop_duplicates('id')[['id','std-psersonal_duration_in_sec','mean-psersonal_duration_in_sec',
                       'min-psersonal_duration_in_sec','max-psersonal_duration_in_sec']]
#-------------------------
# test
#-------------------------

df1 = test.groupby(by = ['id','CustomerID']).query_datetime.min().to_frame('first_time')
df2 = test.groupby(by = ['id','CustomerID']).query_datetime.max().to_frame('last_time')
test = pd.concat([df1,df2], axis =1)
del df1, df2
#計算每個消費者個別使用此程式的持續時間
test['psersonal_duration_in_sec'] = (test['last_time'] - test['first_time']).map(lambda x: x.total_seconds())

test = test.groupby('id').apply(psersonal_duration_estimation).reset_index() \
.drop_duplicates('id')[['id','std-psersonal_duration_in_sec','mean-psersonal_duration_in_sec',
                       'min-psersonal_duration_in_sec','max-psersonal_duration_in_sec']]


#-------------------------
#save
#-------------------------

train.to_csv('../feature/{}/individual_duration_in_sec.csv.gz'.format('train'), index = False, compression='gzip')
test.to_csv('../feature/{}/individual_duration_in_sec.csv.gz'.format('test'), index = False, compression='gzip')
