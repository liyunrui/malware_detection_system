import pandas as pd
import numpy as np
import datetime # datetime preprocessing
import utils # made by author for efficiently dealing with data

##################################
# loading data
##################################
train = pd.read_csv('../input/train.csv.gz', compression='gzip', dtype={'ProductID': str})
test = pd.read_csv('../input/test.csv.gz', compression='gzip', dtype={'ProductID': str})

print('loading finish')

##################################
# pre-processing
##################################

# convert query_datetime(str type) column to datetime type
train['query_datetime'] = pd.to_datetime(train.query_datetime)
test['query_datetime'] = pd.to_datetime(test.query_datetime)

print('pre-processing done')
##################################
# using global window to capture local pattern
##################################
def prior_period_state(x):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    prior_period_point = x.query_datetime.min() + delta / 3
    middle_period_point = x.query_datetime.min() + 2 * delta/3
    #selecting df based on time period
    prior_df = x[x.query_datetime <= prior_period_point]
    if prior_df.empty:
        return 0
    else:
        return prior_df.num_user_at_that_time.sum()
def middle_period_state(x):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    prior_period_point = x.query_datetime.min() + delta / 3
    middle_period_point = x.query_datetime.min() + 2 * delta/3
    #selecting df based on time period
    middle_df = x[(x.query_datetime > prior_period_point ) 
         & (x.query_datetime <= middle_period_point )]
    if middle_df.empty:
        return 0
    else:
        return middle_df.num_user_at_that_time.sum() 
def last_period_state(x):
    '''
    output count in inital, middle, final interval 
    
    parameters:
    ------
    x: DataFrame
    '''
    #time period segment --> prior, middle, last
    delta = x.query_datetime.max() - x.query_datetime.min()
    prior_period_point = x.query_datetime.min() + delta / 3
    middle_period_point = x.query_datetime.min() + 2 * delta/3
    #selecting df based on time period
    last_df = x[x.query_datetime > middle_period_point]
    if last_df.empty:
        return 0
    else:
        return last_df.num_user_at_that_time.sum()  

group_freq = '1440min'
interval = 3
#-------------------------
#train
#-------------------------
#prior_period_state
df1 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq),'CustomerID']).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'customer_count'})

df1 = df1.reset_index('id').reset_index('CustomerID')
df1.drop('customer_count', axis = 1, inplace = True)

df1 = df1.groupby([pd.Grouper(freq = group_freq),'id']).count() # 在這個時間點, 這個id,涉及幾個消費者
df1 = df1.rename(columns = {'CustomerID': 'num_user_at_that_time'})
df1 = df1.reset_index() # for apply()
df1 = df1.groupby('id').apply(prior_period_state).to_frame('prior_period_including_num_user')
df1 = df1.reset_index()
#middle_period_state
df2 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq),'CustomerID']).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'customer_count'})

df2 = df2.reset_index('id').reset_index('CustomerID')
df2.drop('customer_count', axis = 1, inplace = True)

df2 = df2.groupby([pd.Grouper(freq = group_freq),'id']).count() # 在這個時間點, 這個id,涉及幾個消費者
df2 = df2.rename(columns = {'CustomerID': 'num_user_at_that_time'})
df2 = df2.reset_index() # for apply()
df2 = df2.groupby('id').apply(middle_period_state).to_frame('middle_period_including_num_user')
df2 = df2.reset_index()
#last_period_state
df3 = train.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq),'CustomerID']).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'customer_count'})

df3 = df3.reset_index('id').reset_index('CustomerID')
df3.drop('customer_count', axis = 1, inplace = True)

df3 = df3.groupby([pd.Grouper(freq = group_freq),'id']).count() # 在這個時間點, 這個id,涉及幾個消費者
df3 = df3.rename(columns = {'CustomerID': 'num_user_at_that_time'})
df3 = df3.reset_index() # for apply()
df3 = df3.groupby('id').apply(last_period_state).to_frame('last_period_including_num_user')
df3 = df3.reset_index()

#merge
train = pd.merge(df1,df2,on='id',how='left')
train = pd.merge(train,df3,on='id',how='left')
train = train.add_suffix('-interval_{}_freq_{}'.format(interval,group_freq)) \
.rename(columns={'id-interval_{}_freq_{}'.format(interval,group_freq): 'id'})
del df1,df2,df3

#-------------------------
#test
#-------------------------
#prior_period_state: 在前期, 這個電腦程式(id), 涉及幾個消費者
df1 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq),'CustomerID']).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'customer_count'})

df1 = df1.reset_index('id').reset_index('CustomerID')
df1.drop('customer_count', axis = 1, inplace = True)

df1 = df1.groupby([pd.Grouper(freq = group_freq),'id']).count() # 在這個時間點, 這個id,涉及幾個消費者
df1 = df1.rename(columns = {'CustomerID': 'num_user_at_that_time'})
df1 = df1.reset_index() # for apply()
df1 = df1.groupby('id').apply(prior_period_state).to_frame('prior_period_including_num_user')
df1 = df1.reset_index()
#middle_period_state: 在中期, 這個電腦程式(id), 涉及幾個消費者
df2 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq),'CustomerID']).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'customer_count'})

df2 = df2.reset_index('id').reset_index('CustomerID')
df2.drop('customer_count', axis = 1, inplace = True)

df2 = df2.groupby([pd.Grouper(freq = group_freq),'id']).count() # 在這個時間點, 這個id,涉及幾個消費者
df2 = df2.rename(columns = {'CustomerID': 'num_user_at_that_time'})
df2 = df2.reset_index() # for apply()
df2 = df2.groupby('id').apply(middle_period_state).to_frame('middle_period_including_num_user')
df2 = df2.reset_index()
#last_period_state: 在後期, 這個電腦程式(id), 涉及幾個消費者
df3 = test.set_index('query_datetime').groupby(['id',pd.Grouper(freq = group_freq),'CustomerID']).count()[['label']]\
.rename(columns={'query_datetime': 'query_datetime_group', 'label': 'customer_count'})

df3 = df3.reset_index('id').reset_index('CustomerID')
df3.drop('customer_count', axis = 1, inplace = True)

df3 = df3.groupby([pd.Grouper(freq = group_freq),'id']).count() # 在這個時間點, 這個id,涉及幾個消費者
df3 = df3.rename(columns = {'CustomerID': 'num_user_at_that_time'})
df3 = df3.reset_index() # for apply()
df3 = df3.groupby('id').apply(last_period_state).to_frame('last_period_including_num_user')
df3 = df3.reset_index()

#merge
test = pd.merge(df1,df2,on='id',how='left')
test = pd.merge(test,df3,on='id',how='left')
test = test.add_suffix('-interval_{}_freq_{}'.format(interval,group_freq)) \
.rename(columns={'id-interval_{}_freq_{}'.format(interval,group_freq): 'id'})
del df1,df2,df3
#-------------------------
#save
#-------------------------

train.to_csv('../feature/{}/global_window_{}_local_pattern_{}_user.csv.gz'.format('train',interval,group_freq), index = False, compression='gzip')
test.to_csv('../feature/{}/global_window_{}_local_pattern_{}_user.csv.gz'.format('test',interval,group_freq), index = False, compression='gzip')


