import pandas as pd
from xgboost import plot_importance
from xgboost import XGBClassifier
import time
from datetime import datetime
from xgboost import plot_importance
import numpy as np

seed = 1030
def train_val_split(valid_size = 0.2):
    '''
    train/val split by time period
    
    parameters
    -------------
    valid_size: float
    '''
    # randomly pick computer program as validation user from 2017-04-03
    splitting_time = datetime.strptime('2017-04-03', '%Y-%m-%d')    
    valid_id = X_train[X_train['initial_time'] > splitting_time].sample(n = int(X_train.shape[0] * valid_size), random_state = seed ).id 
    is_valid = X_train.id.isin(valid_id) # return a boolean sereis
    #-----
    # train
    #-----
    x_train = X_train[~is_valid].drop(['id','initial_time','final_time'], axis=1)
    y_train = Y_train[~is_valid]
    # for scale_pos_weight
    ratio = 1.0 * y_train.value_counts().iloc[0] / y_train.value_counts().iloc[1]
    #-----
    # val
    #-----
    x_val = X_train[is_valid].drop(['id','initial_time','final_time'], axis=1)
    y_val = Y_train[is_valid]
    
    
    print('FINAL SHAPE')
    print('x_train.shape:{0}'.format(x_train.shape))
    print('x_val.shape:{0}'.format(x_val.shape))
    print('Splitting is fine.') if X_train.shape[0] == x_train.shape[0] + x_val.shape[0] else print('oops')
    return x_train, y_train, x_val, y_val, ratio

#######
# loading data
#######
train = pd.read_csv('../feature/{}/all_features.csv.gz'.format('train'), compression='gzip')
test = pd.read_csv('../feature/{}/all_features.csv.gz'.format('test'), compression='gzip')

train['final_time'] = pd.to_datetime(train.final_time)
train['initial_time'] = pd.to_datetime(train.initial_time)

print( train.shape)
print( 'scale_pos_weight',  1.0 * train.label.value_counts().iloc[0] / train.label.value_counts().iloc[1])

#==============================================================================
# prepare training data
#==============================================================================
Y_train = train['label'] 
X_train = train.drop(['label'], axis=1)
del train
print ('prepartion of training set is done')

#==============================================================================
# feature selection
#==============================================================================
'''
Nested Feature Selection by iteratively removing feature with the highest auc_wo_feature

Note that:
We have to make our seed fixed for effectively comparing impact of different features on our model.
Byt, it may lead to overfitting on validatin set?
'''
features_needed_to_discard = []
best_auc_wo_feature = []
model_performance = []
t = 1
t_1 = 0.9
while (t > t_1):
    # t_1: 上一個model最好的auc_score
    # t: 當下model最好的auc_score
    ##########################################
    # base_model for being thereshold
    ##########################################
    x_train, y_train, x_val, y_val, ratio = train_val_split(valid_size = 0.2)
    feature_names = x_train.columns.tolist()
    print ('larger feature space' ,x_train.shape)

    base_model = XGBClassifier(objective = 'binary:logistic',
                               scale_pos_weight = ratio, 
                               seed = seed
                          )
    base_model.fit(x_train, y_train, 
              eval_metric ='auc' ,eval_set = [(x_val, y_val)],
              early_stopping_rounds = 50) 
    auc_score = base_model.evals_result()['validation_0']['auc'][-1]
    t_1 = auc_score
    ###
    #exp
    ###

    auc_wo_feature = []
    for feature in x_train.columns:
        #######
        # split by time period
        #######
        x_train, y_train, x_val, y_val, ratio = train_val_split(valid_size = 0.2)
        #######
        # remove feature for feature selection
        #######
        x_train = x_train.drop(feature, axis = 1)
        x_val = x_val.drop(feature, axis = 1)
        print ('remove : {}'.format(feature))
        print('x_train.shape:{0}'.format(x_train.shape))
        print('x_val.shape:{0}'.format(x_val.shape))
        ##########################################
        # model testing
        ##########################################
        model = XGBClassifier(objective = 'binary:logistic',
                                   scale_pos_weight = ratio, 
                                   seed = seed
                              )
        model.fit(x_train, y_train, 
                  eval_metric ='auc' ,eval_set = [(x_val, y_val)],
                  early_stopping_rounds = 50) 
        ##########################################
        #auc_without_this_feature
        ##########################################
        auc_score = model.evals_result()['validation_0']['auc'][-1]
        auc_wo_feature.append(auc_score)

    ####
    #remove the worst feature from feautre space, X_train
    ####
    f2 = pd.DataFrame({'feature_name': feature_names, 'auc_wo_feature': auc_wo_feature}).sort_values(by='auc_wo_feature', ascending=False)
    discarded_f = f2.feature_name.iloc[0]    
    X_train = X_train.drop(discarded_f, axis = 1)
    
    features_needed_to_discard.append(discarded_f)
    best_auc_wo_feature.append(f2.auc_wo_feature.iloc[0])
    print ('discarded feature --------------------------> ', discarded_f)
    ####
    #retrain the basemodel with smaller feature space
    ####
    x_train, y_train, x_val, y_val, ratio = train_val_split(valid_size = 0.2)
    print ('smaller feature space' ,x_train.shape)
    base_model = XGBClassifier(objective = 'binary:logistic',
                               scale_pos_weight = ratio, 
                               seed = seed
                          )
    base_model.fit(x_train, y_train, 
              eval_metric ='auc' ,eval_set = [(x_val, y_val)],
              early_stopping_rounds = 50) 
    auc_score = base_model.evals_result()['validation_0']['auc'][-1]
    
    t = auc_score
    model_performance.append((t_1,t))

#####
#write exp_log
#####
f = open('../output/exp_log/discarded_features.txt','w')
f.write('feature')
f.write(' ')
f.write('auc_wo_feature')
f.write('\n')
for fea, auc in zip(features_needed_to_discard, best_auc_wo_feature):
    f.write(fea)
    f.write(' ')
    f.write(str(auc))
    f.write('\n')
f.close()
f = open('../output/exp_log/model_performance.txt','w')
f.write('t_1')
f.write(' ')
f.write('t')
f.write('\n')
for p in model_performance:
    f.write(str(p[0]))
    f.write(' ')
    f.write(str(p[1]))
    f.write('\n')
f.close()