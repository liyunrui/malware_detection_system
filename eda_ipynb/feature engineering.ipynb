{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "from datetime import datetime\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "plt.rcParams['figure.figsize'] = [16, 10] # customizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52518, 86)\n",
      "scale_pos_weight 8.31170212766\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>initial_time</th>\n",
       "      <th>final_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_is_0</th>\n",
       "      <th>log_freq</th>\n",
       "      <th>mean-event_week_of_month</th>\n",
       "      <th>mean-event_day_of_the_month</th>\n",
       "      <th>mean-event_day_of_the_week</th>\n",
       "      <th>...</th>\n",
       "      <th>log_ratio_user_over_time</th>\n",
       "      <th>log_dominance</th>\n",
       "      <th>log_total_count_given_duration</th>\n",
       "      <th>log_ratio_user_over_time_given_duration</th>\n",
       "      <th>log_freq_over_time_given_duration</th>\n",
       "      <th>log_count_customer_given_duration</th>\n",
       "      <th>log_total_count_given_triggering_at_the_same_time</th>\n",
       "      <th>log_ratio_user_over_time_given_triggering_at_the_same_time</th>\n",
       "      <th>log_freq_over_time_given_triggering_at_the_same_time</th>\n",
       "      <th>log_count_customer_given_triggering_at_the_same_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000e2398b12121a85166fed5fe2a3da</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-04 14:24:28</td>\n",
       "      <td>2017-03-08 22:06:44</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.240710</td>\n",
       "      <td>1.021277</td>\n",
       "      <td>4.148936</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470004</td>\n",
       "      <td>1.893112</td>\n",
       "      <td>5.898213</td>\n",
       "      <td>3.654172</td>\n",
       "      <td>4.299693</td>\n",
       "      <td>5.242686</td>\n",
       "      <td>7.064241</td>\n",
       "      <td>5.008883</td>\n",
       "      <td>5.307461</td>\n",
       "      <td>6.775702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001fe8dce14ce099aa6ca8ea5026ea7</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-16 00:23:36</td>\n",
       "      <td>2017-03-21 07:35:55</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>3.247863</td>\n",
       "      <td>18.183762</td>\n",
       "      <td>3.448718</td>\n",
       "      <td>...</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>7.327781</td>\n",
       "      <td>7.254888</td>\n",
       "      <td>5.187011</td>\n",
       "      <td>5.466655</td>\n",
       "      <td>6.974102</td>\n",
       "      <td>7.064241</td>\n",
       "      <td>5.008883</td>\n",
       "      <td>5.307461</td>\n",
       "      <td>6.775702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00027f50019000accc492e5684efc818</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-05 06:59:00</td>\n",
       "      <td>2017-04-08 22:23:27</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.548600</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.328043</td>\n",
       "      <td>3.328042</td>\n",
       "      <td>...</td>\n",
       "      <td>1.871802</td>\n",
       "      <td>6.255270</td>\n",
       "      <td>5.290271</td>\n",
       "      <td>3.067843</td>\n",
       "      <td>3.918985</td>\n",
       "      <td>4.418623</td>\n",
       "      <td>7.064241</td>\n",
       "      <td>5.008883</td>\n",
       "      <td>5.307461</td>\n",
       "      <td>6.775702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00028c9da3573ec50db74b44310ae507</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-15 08:11:22</td>\n",
       "      <td>2017-04-20 22:39:51</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.116323</td>\n",
       "      <td>3.062500</td>\n",
       "      <td>15.347826</td>\n",
       "      <td>4.910326</td>\n",
       "      <td>...</td>\n",
       "      <td>2.987364</td>\n",
       "      <td>7.052817</td>\n",
       "      <td>7.254888</td>\n",
       "      <td>5.187011</td>\n",
       "      <td>5.466655</td>\n",
       "      <td>6.974102</td>\n",
       "      <td>7.064241</td>\n",
       "      <td>5.008883</td>\n",
       "      <td>5.307461</td>\n",
       "      <td>6.775702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003dc8130969abe688cadf5f14ea19f</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-04 08:57:23</td>\n",
       "      <td>2017-04-09 16:49:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.667826</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.259574</td>\n",
       "      <td>2.259574</td>\n",
       "      <td>...</td>\n",
       "      <td>3.120895</td>\n",
       "      <td>6.744779</td>\n",
       "      <td>7.254888</td>\n",
       "      <td>5.187011</td>\n",
       "      <td>5.466655</td>\n",
       "      <td>6.974102</td>\n",
       "      <td>7.064241</td>\n",
       "      <td>5.008883</td>\n",
       "      <td>5.307461</td>\n",
       "      <td>6.775702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  label        initial_time  \\\n",
       "0  0000e2398b12121a85166fed5fe2a3da      0 2017-03-04 14:24:28   \n",
       "1  0001fe8dce14ce099aa6ca8ea5026ea7      0 2017-03-16 00:23:36   \n",
       "2  00027f50019000accc492e5684efc818      0 2017-04-05 06:59:00   \n",
       "3  00028c9da3573ec50db74b44310ae507      0 2017-04-15 08:11:22   \n",
       "4  0003dc8130969abe688cadf5f14ea19f      0 2017-04-04 08:57:23   \n",
       "\n",
       "           final_time  duration  duration_is_0  log_freq  \\\n",
       "0 2017-03-08 22:06:44         4              0  2.240710   \n",
       "1 2017-03-21 07:35:55         5              0  3.663562   \n",
       "2 2017-04-08 22:23:27         3              0  4.548600   \n",
       "3 2017-04-20 22:39:51         5              0  4.116323   \n",
       "4 2017-04-09 16:49:00         5              0  3.667826   \n",
       "\n",
       "   mean-event_week_of_month  mean-event_day_of_the_month  \\\n",
       "0                  1.021277                     4.148936   \n",
       "1                  3.247863                    18.183762   \n",
       "2                  2.000000                     6.328043   \n",
       "3                  3.062500                    15.347826   \n",
       "4                  2.000000                     5.259574   \n",
       "\n",
       "   mean-event_day_of_the_week  \\\n",
       "0                    5.000000   \n",
       "1                    3.448718   \n",
       "2                    3.328042   \n",
       "3                    4.910326   \n",
       "4                    2.259574   \n",
       "\n",
       "                           ...                           \\\n",
       "0                          ...                            \n",
       "1                          ...                            \n",
       "2                          ...                            \n",
       "3                          ...                            \n",
       "4                          ...                            \n",
       "\n",
       "   log_ratio_user_over_time  log_dominance  log_total_count_given_duration  \\\n",
       "0                  0.470004       1.893112                        5.898213   \n",
       "1                  3.688879       7.327781                        7.254888   \n",
       "2                  1.871802       6.255270                        5.290271   \n",
       "3                  2.987364       7.052817                        7.254888   \n",
       "4                  3.120895       6.744779                        7.254888   \n",
       "\n",
       "   log_ratio_user_over_time_given_duration  log_freq_over_time_given_duration  \\\n",
       "0                                 3.654172                           4.299693   \n",
       "1                                 5.187011                           5.466655   \n",
       "2                                 3.067843                           3.918985   \n",
       "3                                 5.187011                           5.466655   \n",
       "4                                 5.187011                           5.466655   \n",
       "\n",
       "   log_count_customer_given_duration  \\\n",
       "0                           5.242686   \n",
       "1                           6.974102   \n",
       "2                           4.418623   \n",
       "3                           6.974102   \n",
       "4                           6.974102   \n",
       "\n",
       "   log_total_count_given_triggering_at_the_same_time  \\\n",
       "0                                           7.064241   \n",
       "1                                           7.064241   \n",
       "2                                           7.064241   \n",
       "3                                           7.064241   \n",
       "4                                           7.064241   \n",
       "\n",
       "   log_ratio_user_over_time_given_triggering_at_the_same_time  \\\n",
       "0                                           5.008883            \n",
       "1                                           5.008883            \n",
       "2                                           5.008883            \n",
       "3                                           5.008883            \n",
       "4                                           5.008883            \n",
       "\n",
       "   log_freq_over_time_given_triggering_at_the_same_time  \\\n",
       "0                                           5.307461      \n",
       "1                                           5.307461      \n",
       "2                                           5.307461      \n",
       "3                                           5.307461      \n",
       "4                                           5.307461      \n",
       "\n",
       "   log_count_customer_given_triggering_at_the_same_time  \n",
       "0                                           6.775702     \n",
       "1                                           6.775702     \n",
       "2                                           6.775702     \n",
       "3                                           6.775702     \n",
       "4                                           6.775702     \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../feature/{}/all_features.csv.gz'.format('train'), compression='gzip')\n",
    "train['final_time'] = pd.to_datetime(train.final_time)\n",
    "train['initial_time'] = pd.to_datetime(train.initial_time)\n",
    "\n",
    "print( train.shape)\n",
    "print( 'scale_pos_weight',  1.0 * train.label.value_counts().iloc[0] / train.label.value_counts().iloc[1])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "print('test')\n",
    "#==============================================================================\n",
    "#load testing set\n",
    "test = pd.read_csv('../feature/{}/all_features.csv.gz'.format('test'), compression='gzip')\n",
    "sub_test = test[['id']]\n",
    "sub_test.columns = ['FileID'] \n",
    "test.drop(['id','label','initial_time','final_time'], axis = 1, inplace = True) # remove sth which is not features\n",
    "\n",
    "\n",
    "# load model from file\n",
    "file_path1 = '../output/model/0318_71/xgb_churn_0.model'\n",
    "file_path2 = '../output/model/0318_71/xgb_churn_1.model'\n",
    "loaded_model1 = pickle.load(open(file_path1, \"rb\"))\n",
    "loaded_model2 = pickle.load(open(file_path2, \"rb\"))\n",
    "models = []\n",
    "models.append(loaded_model1)\n",
    "models.append(loaded_model2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final-num_suspicious_records',\n",
       " 'final_time',\n",
       " 'id',\n",
       " 'initial-num_suspicious_records',\n",
       " 'initial_time',\n",
       " 'label',\n",
       " 'middle-num_suspicious_records'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train.columns.tolist()).difference(set(test.columns.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'middle-num_suspicious_records' in train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'middle-num_suspicious_records' in test.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two features aggregation demo ( given feature A, featureBçš„è®Šå‹•)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for given_col in ['duration','triggering_at_the_same_time']:\n",
    "    #  using aggregation to create features\n",
    "    gby = train.groupby(given_col).count()[['count_product','total_count','ratio_user_over_time','freq_over_time','count_customer']]\n",
    "    # feature names\n",
    "    gby.columns = ['{}_given_{}'.format(col, given_col) for col in gby.columns]\n",
    "    \n",
    "    df = pd.merge(train[['id','duration','triggering_at_the_same_time']], gby, how='left', left_on = given_col, right_index=True)\n",
    "    \n",
    "    # right_index: Use the index from the right DataFrame as the join key\n",
    "    # left_on: Field names to join on in left DataFrame.\n",
    "    #train = pd.merge(test[['id','pickup_hour','dropoff_cluster']], gby, how='left', left_on=given_col, right_index=True)\n",
    "    #test = pd.merge(test[['id','pickup_hour','dropoff_cluster']], gby, how='left', left_on=given_col, right_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
