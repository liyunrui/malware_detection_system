{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "from datetime import datetime\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = [16, 10] # customizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Feature Selection by iteratively removing feature with the highest auc_wo_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(valid_size = 0.2):\n",
    "    '''\n",
    "    train/val split by time period\n",
    "    \n",
    "    parameters\n",
    "    -------------\n",
    "    valid_size: float\n",
    "    '''\n",
    "    # randomly pick computer program as validation user from 2017-04-03\n",
    "    splitting_time = datetime.strptime('2017-04-03', '%Y-%m-%d')    \n",
    "    valid_id = X_train[X_train['initial_time'] > splitting_time].sample(n = int(X_train.shape[0] * valid_size) ).id \n",
    "    is_valid = X_train.id.isin(valid_id) # return a boolean sereis\n",
    "    #-----\n",
    "    # train\n",
    "    #-----\n",
    "    x_train = X_train[~is_valid].drop(['id','initial_time','final_time'], axis=1)\n",
    "    y_train = Y_train[~is_valid]\n",
    "    # for scale_pos_weight\n",
    "    ratio = 1.0 * y_train.value_counts().iloc[0] / y_train.value_counts().iloc[1]\n",
    "    #-----\n",
    "    # val\n",
    "    #-----\n",
    "    x_val = X_train[is_valid].drop(['id','initial_time','final_time'], axis=1)\n",
    "    y_val = Y_train[is_valid]\n",
    "    \n",
    "    \n",
    "    print('FINAL SHAPE')\n",
    "    print('x_train.shape:{0}'.format(x_train.shape))\n",
    "    print('x_val.shape:{0}'.format(x_val.shape))\n",
    "    print('Splitting is fine.') if X_train.shape[0] == x_train.shape[0] + x_val.shape[0] else print('oops')\n",
    "    return x_train, y_train, x_val, y_val, ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52518, 194)\n",
      "scale_pos_weight 8.31170212766\n",
      "prepartion of training set is done\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "# loading data\n",
    "#######\n",
    "train = pd.read_csv('../feature/{}/all_features.csv.gz'.format('train'), compression='gzip')\n",
    "test = pd.read_csv('../feature/{}/all_features.csv.gz'.format('test'), compression='gzip')\n",
    "\n",
    "train['final_time'] = pd.to_datetime(train.final_time)\n",
    "train['initial_time'] = pd.to_datetime(train.initial_time)\n",
    "\n",
    "print( train.shape)\n",
    "print( 'scale_pos_weight',  1.0 * train.label.value_counts().iloc[0] / train.label.value_counts().iloc[1])\n",
    "\n",
    "#==============================================================================\n",
    "# prepare training data\n",
    "#==============================================================================\n",
    "Y_train = train['label'] \n",
    "X_train = train.drop(['label'], axis=1)\n",
    "del train\n",
    "print ('prepartion of training set is done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['id','initial_time','final_time','log_ratio_user_over_time','ratio_product_over_num_user']].head(n = 1000)\n",
    "Y_train = Y_train.head(n = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL SHAPE\n",
      "x_train.shape:(800, 2)\n",
      "x_val.shape:(200, 2)\n",
      "Splitting is fine.\n",
      "larger feature space (800, 2)\n",
      "[0]\tvalidation_0-auc:0.736413\n",
      "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-auc:0.77123\n",
      "[2]\tvalidation_0-auc:0.763757\n",
      "[3]\tvalidation_0-auc:0.763757\n",
      "[4]\tvalidation_0-auc:0.772758\n",
      "[5]\tvalidation_0-auc:0.77106\n",
      "[6]\tvalidation_0-auc:0.774117\n",
      "[7]\tvalidation_0-auc:0.78159\n",
      "[8]\tvalidation_0-auc:0.787704\n",
      "[9]\tvalidation_0-auc:0.787364\n",
      "[10]\tvalidation_0-auc:0.782269\n",
      "[11]\tvalidation_0-auc:0.785666\n",
      "[12]\tvalidation_0-auc:0.786005\n",
      "[13]\tvalidation_0-auc:0.785156\n",
      "[14]\tvalidation_0-auc:0.784477\n",
      "[15]\tvalidation_0-auc:0.784477\n",
      "[16]\tvalidation_0-auc:0.787534\n",
      "[17]\tvalidation_0-auc:0.78142\n",
      "[18]\tvalidation_0-auc:0.78142\n",
      "[19]\tvalidation_0-auc:0.783798\n",
      "[20]\tvalidation_0-auc:0.783798\n",
      "[21]\tvalidation_0-auc:0.783798\n",
      "[22]\tvalidation_0-auc:0.783118\n",
      "[23]\tvalidation_0-auc:0.783118\n",
      "[24]\tvalidation_0-auc:0.783118\n",
      "[25]\tvalidation_0-auc:0.782099\n",
      "[26]\tvalidation_0-auc:0.782099\n",
      "[27]\tvalidation_0-auc:0.778702\n",
      "[28]\tvalidation_0-auc:0.778702\n",
      "[29]\tvalidation_0-auc:0.780061\n",
      "[30]\tvalidation_0-auc:0.78108\n",
      "[31]\tvalidation_0-auc:0.78108\n",
      "[32]\tvalidation_0-auc:0.78108\n",
      "[33]\tvalidation_0-auc:0.782779\n",
      "[34]\tvalidation_0-auc:0.783118\n",
      "[35]\tvalidation_0-auc:0.779042\n",
      "[36]\tvalidation_0-auc:0.775985\n",
      "[37]\tvalidation_0-auc:0.776325\n",
      "[38]\tvalidation_0-auc:0.784817\n",
      "[39]\tvalidation_0-auc:0.784817\n",
      "[40]\tvalidation_0-auc:0.784817\n",
      "[41]\tvalidation_0-auc:0.779212\n",
      "[42]\tvalidation_0-auc:0.779552\n",
      "[43]\tvalidation_0-auc:0.777683\n",
      "[44]\tvalidation_0-auc:0.780061\n",
      "[45]\tvalidation_0-auc:0.780061\n",
      "[46]\tvalidation_0-auc:0.780061\n",
      "[47]\tvalidation_0-auc:0.783118\n",
      "[48]\tvalidation_0-auc:0.78142\n",
      "[49]\tvalidation_0-auc:0.779721\n",
      "[50]\tvalidation_0-auc:0.777004\n",
      "[51]\tvalidation_0-auc:0.78108\n",
      "[52]\tvalidation_0-auc:0.78108\n",
      "[53]\tvalidation_0-auc:0.783458\n",
      "[54]\tvalidation_0-auc:0.784137\n",
      "[55]\tvalidation_0-auc:0.782099\n",
      "[56]\tvalidation_0-auc:0.782099\n",
      "[57]\tvalidation_0-auc:0.780571\n",
      "[58]\tvalidation_0-auc:0.783628\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-auc:0.787704\n",
      "\n",
      "FINAL SHAPE\n",
      "x_train.shape:(800, 2)\n",
      "x_val.shape:(200, 2)\n",
      "Splitting is fine.\n",
      "remove : log_ratio_user_over_time\n",
      "x_train.shape:(800, 1)\n",
      "x_val.shape:(200, 1)\n",
      "[0]\tvalidation_0-auc:0.746342\n",
      "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-auc:0.747672\n",
      "[2]\tvalidation_0-auc:0.749135\n",
      "[3]\tvalidation_0-auc:0.761107\n",
      "[4]\tvalidation_0-auc:0.765363\n",
      "[5]\tvalidation_0-auc:0.766693\n",
      "[6]\tvalidation_0-auc:0.767491\n",
      "[7]\tvalidation_0-auc:0.767491\n",
      "[8]\tvalidation_0-auc:0.766959\n",
      "[9]\tvalidation_0-auc:0.768555\n",
      "[10]\tvalidation_0-auc:0.76789\n",
      "[11]\tvalidation_0-auc:0.776536\n",
      "[12]\tvalidation_0-auc:0.79037\n",
      "[13]\tvalidation_0-auc:0.783985\n",
      "[14]\tvalidation_0-auc:0.784251\n",
      "[15]\tvalidation_0-auc:0.784251\n",
      "[16]\tvalidation_0-auc:0.779995\n",
      "[17]\tvalidation_0-auc:0.779995\n",
      "[18]\tvalidation_0-auc:0.784783\n",
      "[19]\tvalidation_0-auc:0.776802\n",
      "[20]\tvalidation_0-auc:0.776802\n",
      "[21]\tvalidation_0-auc:0.783719\n",
      "[22]\tvalidation_0-auc:0.783719\n",
      "[23]\tvalidation_0-auc:0.782921\n",
      "[24]\tvalidation_0-auc:0.782389\n",
      "[25]\tvalidation_0-auc:0.782921\n",
      "[26]\tvalidation_0-auc:0.776004\n",
      "[27]\tvalidation_0-auc:0.776004\n",
      "[28]\tvalidation_0-auc:0.776004\n",
      "[29]\tvalidation_0-auc:0.776004\n",
      "[30]\tvalidation_0-auc:0.776004\n",
      "[31]\tvalidation_0-auc:0.779729\n",
      "[32]\tvalidation_0-auc:0.779729\n",
      "[33]\tvalidation_0-auc:0.778931\n",
      "[34]\tvalidation_0-auc:0.779197\n",
      "[35]\tvalidation_0-auc:0.776004\n",
      "[36]\tvalidation_0-auc:0.776004\n",
      "[37]\tvalidation_0-auc:0.775871\n",
      "[38]\tvalidation_0-auc:0.767624\n",
      "[39]\tvalidation_0-auc:0.767624\n",
      "[40]\tvalidation_0-auc:0.764432\n",
      "[41]\tvalidation_0-auc:0.761506\n",
      "[42]\tvalidation_0-auc:0.763368\n",
      "[43]\tvalidation_0-auc:0.763368\n",
      "[44]\tvalidation_0-auc:0.763368\n",
      "[45]\tvalidation_0-auc:0.765762\n",
      "[46]\tvalidation_0-auc:0.765762\n",
      "[47]\tvalidation_0-auc:0.765762\n",
      "[48]\tvalidation_0-auc:0.764432\n",
      "[49]\tvalidation_0-auc:0.764432\n",
      "[50]\tvalidation_0-auc:0.764432\n",
      "[51]\tvalidation_0-auc:0.764432\n",
      "[52]\tvalidation_0-auc:0.76789\n",
      "[53]\tvalidation_0-auc:0.768955\n",
      "[54]\tvalidation_0-auc:0.768955\n",
      "[55]\tvalidation_0-auc:0.768955\n",
      "[56]\tvalidation_0-auc:0.765762\n",
      "[57]\tvalidation_0-auc:0.76656\n",
      "[58]\tvalidation_0-auc:0.771349\n",
      "[59]\tvalidation_0-auc:0.771349\n",
      "[60]\tvalidation_0-auc:0.771349\n",
      "[61]\tvalidation_0-auc:0.76789\n",
      "[62]\tvalidation_0-auc:0.768156\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-auc:0.79037\n",
      "\n",
      "FINAL SHAPE\n",
      "x_train.shape:(800, 2)\n",
      "x_val.shape:(200, 2)\n",
      "Splitting is fine.\n",
      "remove : ratio_product_over_num_user\n",
      "x_train.shape:(800, 1)\n",
      "x_val.shape:(200, 1)\n",
      "[0]\tvalidation_0-auc:0.70757\n",
      "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-auc:0.705281\n",
      "[2]\tvalidation_0-auc:0.727106\n",
      "[3]\tvalidation_0-auc:0.709707\n",
      "[4]\tvalidation_0-auc:0.711386\n",
      "[5]\tvalidation_0-auc:0.710775\n",
      "[6]\tvalidation_0-auc:0.710775\n",
      "[7]\tvalidation_0-auc:0.710775\n",
      "[8]\tvalidation_0-auc:0.717491\n",
      "[9]\tvalidation_0-auc:0.733669\n",
      "[10]\tvalidation_0-auc:0.73428\n",
      "[11]\tvalidation_0-auc:0.73428\n",
      "[12]\tvalidation_0-auc:0.73428\n",
      "[13]\tvalidation_0-auc:0.73428\n",
      "[14]\tvalidation_0-auc:0.73428\n",
      "[15]\tvalidation_0-auc:0.73428\n",
      "[16]\tvalidation_0-auc:0.73428\n",
      "[17]\tvalidation_0-auc:0.73428\n",
      "[18]\tvalidation_0-auc:0.73428\n",
      "[19]\tvalidation_0-auc:0.73428\n",
      "[20]\tvalidation_0-auc:0.732448\n",
      "[21]\tvalidation_0-auc:0.732448\n",
      "[22]\tvalidation_0-auc:0.732448\n",
      "[23]\tvalidation_0-auc:0.738095\n",
      "[24]\tvalidation_0-auc:0.738095\n",
      "[25]\tvalidation_0-auc:0.738095\n",
      "[26]\tvalidation_0-auc:0.738095\n",
      "[27]\tvalidation_0-auc:0.73779\n",
      "[28]\tvalidation_0-auc:0.73779\n",
      "[29]\tvalidation_0-auc:0.73779\n",
      "[30]\tvalidation_0-auc:0.73779\n",
      "[31]\tvalidation_0-auc:0.751526\n",
      "[32]\tvalidation_0-auc:0.751526\n",
      "[33]\tvalidation_0-auc:0.750305\n",
      "[34]\tvalidation_0-auc:0.75351\n",
      "[35]\tvalidation_0-auc:0.75351\n",
      "[36]\tvalidation_0-auc:0.752442\n",
      "[37]\tvalidation_0-auc:0.752442\n",
      "[38]\tvalidation_0-auc:0.752442\n",
      "[39]\tvalidation_0-auc:0.751221\n",
      "[40]\tvalidation_0-auc:0.746337\n",
      "[41]\tvalidation_0-auc:0.746337\n",
      "[42]\tvalidation_0-auc:0.746337\n",
      "[43]\tvalidation_0-auc:0.746337\n",
      "[44]\tvalidation_0-auc:0.746337\n",
      "[45]\tvalidation_0-auc:0.748321\n",
      "[46]\tvalidation_0-auc:0.748321\n",
      "[47]\tvalidation_0-auc:0.747405\n",
      "[48]\tvalidation_0-auc:0.747405\n",
      "[49]\tvalidation_0-auc:0.747405\n",
      "[50]\tvalidation_0-auc:0.753205\n",
      "[51]\tvalidation_0-auc:0.75351\n",
      "[52]\tvalidation_0-auc:0.75351\n",
      "[53]\tvalidation_0-auc:0.752595\n",
      "[54]\tvalidation_0-auc:0.737332\n",
      "[55]\tvalidation_0-auc:0.737332\n",
      "[56]\tvalidation_0-auc:0.7384\n",
      "[57]\tvalidation_0-auc:0.734737\n",
      "[58]\tvalidation_0-auc:0.734737\n",
      "[59]\tvalidation_0-auc:0.73138\n",
      "[60]\tvalidation_0-auc:0.742521\n",
      "[61]\tvalidation_0-auc:0.742521\n",
      "[62]\tvalidation_0-auc:0.742521\n",
      "[63]\tvalidation_0-auc:0.74069\n",
      "[64]\tvalidation_0-auc:0.740995\n",
      "[65]\tvalidation_0-auc:0.74069\n",
      "[66]\tvalidation_0-auc:0.742827\n",
      "[67]\tvalidation_0-auc:0.742827\n",
      "[68]\tvalidation_0-auc:0.742827\n",
      "[69]\tvalidation_0-auc:0.742827\n",
      "[70]\tvalidation_0-auc:0.741606\n",
      "[71]\tvalidation_0-auc:0.737332\n",
      "[72]\tvalidation_0-auc:0.737027\n",
      "[73]\tvalidation_0-auc:0.737637\n",
      "[74]\tvalidation_0-auc:0.736416\n",
      "[75]\tvalidation_0-auc:0.736416\n",
      "[76]\tvalidation_0-auc:0.736416\n",
      "[77]\tvalidation_0-auc:0.736416\n",
      "[78]\tvalidation_0-auc:0.736111\n",
      "[79]\tvalidation_0-auc:0.736416\n",
      "[80]\tvalidation_0-auc:0.737027\n",
      "[81]\tvalidation_0-auc:0.737027\n",
      "[82]\tvalidation_0-auc:0.736264\n",
      "[83]\tvalidation_0-auc:0.736264\n",
      "[84]\tvalidation_0-auc:0.735043\n",
      "Stopping. Best iteration:\n",
      "[34]\tvalidation_0-auc:0.75351\n",
      "\n",
      "discarded feature -------------------------->  log_ratio_user_over_time\n",
      "FINAL SHAPE\n",
      "x_train.shape:(800, 1)\n",
      "x_val.shape:(200, 1)\n",
      "Splitting is fine.\n",
      "smaller feature space (800, 1)\n",
      "[0]\tvalidation_0-auc:0.757924\n",
      "Will train until validation_0-auc hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-auc:0.762576\n",
      "[2]\tvalidation_0-auc:0.762576\n",
      "[3]\tvalidation_0-auc:0.762576\n",
      "[4]\tvalidation_0-auc:0.762576\n",
      "[5]\tvalidation_0-auc:0.767665\n",
      "[6]\tvalidation_0-auc:0.756906\n",
      "[7]\tvalidation_0-auc:0.748183\n",
      "[8]\tvalidation_0-auc:0.747456\n",
      "[9]\tvalidation_0-auc:0.754434\n",
      "[10]\tvalidation_0-auc:0.754434\n",
      "[11]\tvalidation_0-auc:0.754434\n",
      "[12]\tvalidation_0-auc:0.754144\n",
      "[13]\tvalidation_0-auc:0.754144\n",
      "[14]\tvalidation_0-auc:0.760832\n",
      "[15]\tvalidation_0-auc:0.757924\n",
      "[16]\tvalidation_0-auc:0.764321\n",
      "[17]\tvalidation_0-auc:0.764321\n",
      "[18]\tvalidation_0-auc:0.764321\n",
      "[19]\tvalidation_0-auc:0.764321\n",
      "[20]\tvalidation_0-auc:0.764903\n",
      "[21]\tvalidation_0-auc:0.764903\n",
      "[22]\tvalidation_0-auc:0.766502\n",
      "[23]\tvalidation_0-auc:0.766502\n",
      "[24]\tvalidation_0-auc:0.766502\n",
      "[25]\tvalidation_0-auc:0.766502\n",
      "[26]\tvalidation_0-auc:0.766502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\tvalidation_0-auc:0.761268\n",
      "[28]\tvalidation_0-auc:0.761268\n",
      "[29]\tvalidation_0-auc:0.761268\n",
      "[30]\tvalidation_0-auc:0.761268\n",
      "[31]\tvalidation_0-auc:0.764466\n",
      "[32]\tvalidation_0-auc:0.764466\n",
      "[33]\tvalidation_0-auc:0.764466\n",
      "[34]\tvalidation_0-auc:0.764466\n",
      "[35]\tvalidation_0-auc:0.764466\n",
      "[36]\tvalidation_0-auc:0.764466\n",
      "[37]\tvalidation_0-auc:0.764466\n",
      "[38]\tvalidation_0-auc:0.766502\n",
      "[39]\tvalidation_0-auc:0.766502\n",
      "[40]\tvalidation_0-auc:0.766793\n",
      "[41]\tvalidation_0-auc:0.766793\n",
      "[42]\tvalidation_0-auc:0.766793\n",
      "[43]\tvalidation_0-auc:0.76592\n",
      "[44]\tvalidation_0-auc:0.765484\n",
      "[45]\tvalidation_0-auc:0.765484\n",
      "[46]\tvalidation_0-auc:0.765484\n",
      "[47]\tvalidation_0-auc:0.761122\n",
      "[48]\tvalidation_0-auc:0.758505\n",
      "[49]\tvalidation_0-auc:0.758505\n",
      "[50]\tvalidation_0-auc:0.758505\n",
      "[51]\tvalidation_0-auc:0.756761\n",
      "[52]\tvalidation_0-auc:0.756761\n",
      "[53]\tvalidation_0-auc:0.756761\n",
      "[54]\tvalidation_0-auc:0.756761\n",
      "[55]\tvalidation_0-auc:0.756761\n",
      "Stopping. Best iteration:\n",
      "[5]\tvalidation_0-auc:0.767665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# feature selection\n",
    "#==============================================================================\n",
    "\n",
    "features_needed_to_discard = []\n",
    "best_auc_wo_feature = []\n",
    "model_performance = []\n",
    "t = 1\n",
    "t_1 = 0.9\n",
    "while (t > t_1):\n",
    "    # t_1: 上一個model最好的auc_score\n",
    "    # t: 當下model最好的auc_score\n",
    "    ##########################################\n",
    "    # base_model for being thereshold\n",
    "    ##########################################\n",
    "    x_train, y_train, x_val, y_val, ratio = train_val_split(valid_size = 0.2)\n",
    "    feature_names = x_train.columns.tolist()\n",
    "    print ('larger feature space' ,x_train.shape)\n",
    "\n",
    "    base_model = XGBClassifier(objective = 'binary:logistic',\n",
    "                               scale_pos_weight = ratio, \n",
    "                               seed = 72\n",
    "                          )\n",
    "    base_model.fit(x_train, y_train, \n",
    "              eval_metric ='auc' ,eval_set = [(x_val, y_val)],\n",
    "              early_stopping_rounds = 50) \n",
    "    auc_score = base_model.evals_result()['validation_0']['auc'][-1]\n",
    "    auc_wo_feature.append(auc_score)\n",
    "\n",
    "    t_1 = auc_score\n",
    "    ###\n",
    "    #exp\n",
    "    ###\n",
    "\n",
    "    auc_wo_feature = []\n",
    "    for feature in x_train.columns:\n",
    "        #######\n",
    "        # split by time period\n",
    "        #######\n",
    "        x_train, y_train, x_val, y_val, ratio = train_val_split(valid_size = 0.2)\n",
    "        #######\n",
    "        # remove feature for feature selection\n",
    "        #######\n",
    "        x_train = x_train.drop(feature, axis = 1)\n",
    "        x_val = x_val.drop(feature, axis = 1)\n",
    "        print ('remove : {}'.format(feature))\n",
    "        print('x_train.shape:{0}'.format(x_train.shape))\n",
    "        print('x_val.shape:{0}'.format(x_val.shape))\n",
    "        ##########################################\n",
    "        # base_model for getting feature importance as thereshold\n",
    "        ##########################################\n",
    "        model = XGBClassifier(objective = 'binary:logistic',\n",
    "                                   scale_pos_weight = ratio, \n",
    "                                   seed = 72\n",
    "                              )\n",
    "        model.fit(x_train, y_train, \n",
    "                  eval_metric ='auc' ,eval_set = [(x_val, y_val)],\n",
    "                  early_stopping_rounds = 50) \n",
    "        ##########################################\n",
    "        #auc_without_this_feature\n",
    "        ##########################################\n",
    "        auc_score = model.evals_result()['validation_0']['auc'][-1]\n",
    "        auc_wo_feature.append(auc_score)\n",
    "\n",
    "    ####\n",
    "    #remove the worst feature from feautre space, X_train\n",
    "    ####\n",
    "    f2 = pd.DataFrame({'feature_name': feature_names, 'auc_wo_feature': auc_wo_feature}).sort_values(by='auc_wo_feature', ascending=False)\n",
    "    discarded_f = f2.feature_name.iloc[0]    \n",
    "    X_train = X_train.drop(discarded_f, axis = 1)\n",
    "    \n",
    "    features_needed_to_discard.append(discarded_f)\n",
    "    best_auc_wo_feature.append(f2.auc_wo_feature.iloc[0])\n",
    "    print ('discarded feature --------------------------> ', discarded_f)\n",
    "    ####\n",
    "    #retrain the basemodel with smaller feature space\n",
    "    ####\n",
    "    x_train, y_train, x_val, y_val, ratio = train_val_split(valid_size = 0.2)\n",
    "    print ('smaller feature space' ,x_train.shape)\n",
    "    base_model = XGBClassifier(objective = 'binary:logistic',\n",
    "                               scale_pos_weight = ratio, \n",
    "                               seed = 72\n",
    "                          )\n",
    "    base_model.fit(x_train, y_train, \n",
    "              eval_metric ='auc' ,eval_set = [(x_val, y_val)],\n",
    "              early_stopping_rounds = 50) \n",
    "    auc_score = base_model.evals_result()['validation_0']['auc'][-1]\n",
    "    \n",
    "    t = auc_score\n",
    "    model_performance.append((t_1,t))\n",
    "\n",
    "#####\n",
    "#write exp_log\n",
    "#####\n",
    "f = open('../output/exp_log/discarded_features.txt','w')\n",
    "for fea, auc in zip(features_needed_to_discard, best_auc_wo_feature):\n",
    "    f.write(fea)\n",
    "    f.write(' ')\n",
    "    f.write(str(auc))\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "f = open('../output/exp_log/model_performance.txt','w')\n",
    "f.write('t_1')\n",
    "f.write(' ')\n",
    "f.write('t')\n",
    "f.write('\\n')\n",
    "for p in model_performance:\n",
    "    f.write(str(p[0]))\n",
    "    f.write(' ')\n",
    "    f.write(str(p[1]))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#write exp_log\n",
    "#####\n",
    "f = open('../output/exp_log/discarded_features.txt','w')\n",
    "for fea, auc in zip(features_needed_to_discard, best_auc_wo_feature):\n",
    "    f.write(fea)\n",
    "    f.write(' ')\n",
    "    f.write(str(auc))\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "f = open('../output/exp_log/model_performance.txt','w')\n",
    "f.write('t_1')\n",
    "f.write(' ')\n",
    "f.write('t')\n",
    "f.write('\\n')\n",
    "for p in model_performance:\n",
    "    f.write(str(p[0]))\n",
    "    f.write(' ')\n",
    "    f.write(str(p[1]))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
